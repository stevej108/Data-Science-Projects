{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOJ4gE0HHnWxnr+zLTqWD9q"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Extract-Transform-Load (ETL) pipeline to import excel data, process the data for visualizations, and load the data to Power Bi."],"metadata":{"id":"YgAVMtJFeltA"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"3hRxs5jCekEt"},"outputs":[],"source":["# Importing libraries\n","\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import plotly.express as px\n"]},{"cell_type":"code","source":["# Extraction of data\n","\n","def extract_excel(file_path: str, sheet_names: list) -> dict:\n","  \"\"\"\n","  Extracts specfied sheets from Excel file and returns a dictionary of dataframes.\n","\n","  Parameters:\n","  file_path (str): Path to the Excel file.\n","  sheet_names (list): List of sheet names to extract.\n","\n","  Returns:\n","  dict: Dictionary of dataframes, where keys are sheet names and values are dataframes.\n","\n","  \"\"\"\n","  try:\n","    data=pd.read_excel(file_path, sheet_name=sheet_names)\n","    return data\n","  except Exception as e:\n","    print(f\"Error extracting sheets: {e}\")\n","    return {}\n","\n","  # Example:\n","  # file_path = 'data.xlsx'\n","  sheets_to_extract = ['Sheet1', 'Sheet2']\n","  extracted_data = extract_excel(file_path, sheets_to_extract)\n","  print(extracted_data.keys())"],"metadata":{"id":"zD3PzPXte-ie"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Data Transformation\n","\n","def transform_data(df_fct: pd.DataFrame, df_ct: pd.DataFrame) -> pd.DataFrame:\n","    \"\"\"\n","    Transforms the extracted dataframes by renaming columns, changing data types,\n","    dropping unnecessary columns, and merging them into a single dataframe.\n","\n","    Parameters:\n","        df_fct (pd.DataFrame): DataFrame extracted from the first sheet.\n","        df_ct (pd.DataFrame): DataFrame extracted from the second sheet.\n","\n","    Returns:\n","        pd.DataFrame: The transformed and merged dataframe.\n","    \"\"\"\n","    df_fct.rename(columns={'Unnamed: 0': 'ID'}, inplace=True)\n","    df_fct.drop([0], inplace=True)\n","    df_fct.reset_index(drop=True, inplace=True)\n","    df_fct[\"Vessel#\"] = df_fct['Vessel#'].astype(str)\n","    df_fct[\"Batch ID FCT\"] = df_fct['Batch ID FCT'].astype(str)\n","    df_fct[\"Sample ID\"] = df_fct['Sample ID'].astype(str)\n","    df_fct.drop(columns=['mass (mg)', 'mg/mm', \"ID\"], inplace=True)\n","\n","    df_ct[\"Vessel#\"] = df_ct['Vessel#'].astype(str)\n","    df_ct[\"Batch ID\"] = df_ct['Batch ID'].astype(str)\n","    df_ct[\"Sample ID\"] = df_ct['Sample ID'].astype(str)\n","    df_ct['SamplingLocation'] = df_ct['SamplingLocation'].astype(str)\n","    df_ct.drop(columns=['mass (mg)', 'mg/mm', \"ID\"], inplace=True)\n","\n","    df_fct.rename(columns={'15 min release%': '15 min release %'}, inplace=True)\n","    df_fct.rename(columns={'Batch ID FCT': 'Batch ID'}, inplace=True)\n","\n","    df_both = pd.concat([df_fct, df_ct], axis=0)\n","\n","    return df_both\n","\n","# Example usage:\n","# file_path = \"data.xlsx\"\n","# sheets_to_extract = [\"Sheet1\", \"Sheet2\"]\n","# extracted_data = extract_excel(file_path, sheets_to_extract)\n","# df_transformed = transform_data(extracted_data[\"Sheet1\"], extracted_data[\"Sheet2\"])\n","# print(df_transformed.head())"],"metadata":{"id":"mH6xsPM0gjlg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Saving/Loading Data for visualization\n","\n","def load_to_csv(df: pd.DataFrame, output_path: str):\n","    \"\"\"\n","    Saves the cleaned dataframe to a CSV file.\n","\n","    Parameters:\n","        df (pd.DataFrame): The cleaned dataframe.\n","        output_path (str): The path where the CSV file will be saved.\n","    \"\"\"\n","    df.to_csv(output_path, index=False)\n","    print(f\"Data successfully saved to {output_path}\")\n","\n","# Example usage:\n","# output_file = \"cleaned_data.csv\"\n","# load_to_csv(df_transformed, output_file)"],"metadata":{"id":"RzYFslK6g98H"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# The ETL pipeline to run\n","\n","def ETL(file_path: str, sheet_names: list, output_path: str):\n","    \"\"\"\n","    Complete ETL pipeline to extract, transform, and load data.\n","\n","    Parameters:\n","        file_path (str): The path to the Excel file.\n","        sheet_names (list): List of sheet names to extract.\n","        output_path (str): The path to save the transformed data as a CSV file.\n","    \"\"\"\n","    extracted_data = extract_excel(file_path, sheet_names)\n","    if not extracted_data:\n","        print(\"Extraction failed. Exiting ETL process.\")\n","        return\n","\n","    df_transformed = transform_data(extracted_data[sheet_names[0]], extracted_data[sheet_names[1]])\n","    load_to_csv(df_transformed, output_path)\n","\n","# Example usage:\n","# file_path = \"data.xlsx\"\n","# sheets_to_extract = [\"Sheet1\", \"Sheet2\"]\n","# output_file = \"cleaned_data.csv\"\n","# ETL(file_path, sheets_to_extract, output_file)"],"metadata":{"id":"cMKyazsmhh7_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["file_path = \"/content/20250305_Atozet disso data_clean.xlsx\"\n","sheets_to_extract = [\"FCT\", \"CT\"]\n","output_file = \"atozet_data.csv\"\n","ETL(file_path, sheets_to_extract, output_file)"],"metadata":{"id":"nWVcgChAhlZ_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1741195290987,"user_tz":300,"elapsed":87,"user":{"displayName":"justin steve","userId":"16289008734725135998"}},"outputId":"befbe292-0374-40b9-f8cd-17dbd32bb675"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Data successfully saved to atozet_data.csv\n"]}]}]}
